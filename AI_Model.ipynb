{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkvX+z0aUa0ya2hHDeHs0F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EdDee296/seizure-forecasting-system/blob/EdDee/AI_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **0. Install dependencies**"
      ],
      "metadata": {
        "id": "0nX47gdbk_JJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install Dependencies**"
      ],
      "metadata": {
        "id": "fPMDYwC3lJb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install tensorflow numpy pandas scipy scikit-learn matplotlib\n"
      ],
      "metadata": {
        "id": "P4AfOdrXlE46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Verify Installation**"
      ],
      "metadata": {
        "id": "9fqcguFhlLtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import sklearn\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"NumPy version:\", np.__version__)\n",
        "print(\"Pandas version:\", pd.__version__)\n",
        "print(\"SciPy version:\", scipy.__version__)\n",
        "print(\"Scikit-Learn version:\", sklearn.__version__)"
      ],
      "metadata": {
        "id": "6H2E3YHilOJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Data Processing**\n",
        "**Import Libraries**"
      ],
      "metadata": {
        "id": "9cmfpmYnjjyZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGbFlhOEjaLY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy import signal\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Extraction Function**"
      ],
      "metadata": {
        "id": "EKWs6A0CjzgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(window: pd.DataFrame, feature_config: dict) -> np.ndarray:\n",
        "    features = []\n",
        "    for signal_type, channels in feature_config.items():\n",
        "        for channel in channels:\n",
        "            data = window[f'{signal_type}_{channel}']\n",
        "            # Time domain features\n",
        "            features.extend([\n",
        "                np.mean(data),\n",
        "                np.std(data),\n",
        "                np.median(data),\n",
        "                np.max(data),\n",
        "                np.min(data)\n",
        "            ])\n",
        "            # Frequency domain features\n",
        "            if signal_type in ['acc', 'eda']:\n",
        "                freqs, psd = signal.welch(data)\n",
        "                features.extend([\n",
        "                    np.sum(psd),\n",
        "                    np.mean(psd),\n",
        "                    freqs[np.argmax(psd)]\n",
        "                ])\n",
        "    return np.array(features)"
      ],
      "metadata": {
        "id": "uMAP0cQyj2p0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Processing Function**"
      ],
      "metadata": {
        "id": "ZPfnstBtj8Zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_wearable_data(raw_data: pd.DataFrame) -> np.ndarray:\n",
        "    features = {\n",
        "        'acc': ['x', 'y', 'z'],\n",
        "        'eda': ['conductance'],\n",
        "        'hr': ['bpm'],\n",
        "        'temp': ['celsius']\n",
        "    }\n",
        "    window_size = 60 * 30  # 30 minute windows\n",
        "    overlap = 0.5          # 50% overlap\n",
        "    processed_windows = []\n",
        "    for start in range(0, len(raw_data), int(window_size * overlap)):\n",
        "        window = raw_data.iloc[start:start + window_size]\n",
        "        if len(window) == window_size:\n",
        "            window_features = extract_features(window, features)\n",
        "            processed_windows.append(window_features)\n",
        "    return np.array(processed_windows)\n"
      ],
      "metadata": {
        "id": "F9QjjlEMj4V6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. LSTM Model Architecture**\n",
        "**Import TensorFlow Libraries**"
      ],
      "metadata": {
        "id": "iJ1QNmbQj-ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "3YkJ3AWqkDBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build Model Function**"
      ],
      "metadata": {
        "id": "XK65rFIhkRTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape: tuple, lstm_units: list = [64, 32], dropout: float = 0.5) -> tf.keras.Model:\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(lstm_units[0], input_shape=input_shape, return_sequences=True))\n",
        "    model.add(Dropout(dropout))\n",
        "    for units in lstm_units[1:]:\n",
        "        model.add(LSTM(units, return_sequences=False))\n",
        "        model.add(Dropout(dropout))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['AUC'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "JadvLXM2kUUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Training Pipeline**\n",
        "**Seizure Forecaster Class**"
      ],
      "metadata": {
        "id": "1bb5T5u0kFMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SeizureForecaster:\n",
        "    def __init__(self, prediction_horizon: int = 30, sequence_length: int = 60):\n",
        "        self.prediction_horizon = prediction_horizon\n",
        "        self.sequence_length = sequence_length\n",
        "        self.model = None\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def prepare_sequences(self, features: np.ndarray, labels: np.ndarray) -> tuple:\n",
        "        X, y = [], []\n",
        "        for i in range(len(features) - self.sequence_length):\n",
        "            X.append(features[i:i + self.sequence_length])\n",
        "            future_window = labels[i + self.sequence_length: i + self.sequence_length + self.prediction_horizon]\n",
        "            y.append(1 if np.any(future_window) else 0)\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    def train(self, train_data: tuple, val_data: tuple, epochs: int = 100, batch_size: int = 32):\n",
        "        X_train, y_train = train_data\n",
        "        X_val, y_val = val_data\n",
        "        X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])\n",
        "        X_val_reshaped = X_val.reshape(-1, X_val.shape[-1])\n",
        "        self.scaler.fit(X_train_reshaped)\n",
        "        X_train_scaled = self.scaler.transform(X_train_reshaped).reshape(X_train.shape)\n",
        "        X_val_scaled = self.scaler.transform(X_val_reshaped).reshape(X_val.shape)\n",
        "        self.model = build_model(input_shape=(self.sequence_length, X_train.shape[-1]))\n",
        "        history = self.model.fit(\n",
        "            X_train_scaled, y_train,\n",
        "            validation_data=(X_val_scaled, y_val),\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=10, restore_best_weights=True)]\n",
        "        )\n",
        "        return history\n",
        "\n",
        "    def predict(self, features: np.ndarray) -> np.ndarray:\n",
        "        features_scaled = self.scaler.transform(features.reshape(-1, features.shape[-1])).reshape(features.shape)\n",
        "        return self.model.predict(features_scaled)\n"
      ],
      "metadata": {
        "id": "4dakqYESka2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Evaluation**\n",
        "**Import Evaluation Libraries**"
      ],
      "metadata": {
        "id": "uMkLBNGPkde2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, precision_recall_curve\n"
      ],
      "metadata": {
        "id": "Nkcl0B55khc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation Function**"
      ],
      "metadata": {
        "id": "6IQ5a4Vvkrdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_forecaster(y_true: np.ndarray, y_pred: np.ndarray, random_predictions: np.ndarray) -> dict:\n",
        "    actual_auc = roc_auc_score(y_true, y_pred)\n",
        "    random_auc = roc_auc_score(y_true, random_predictions)\n",
        "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
        "    return {\n",
        "        'auc_roc': actual_auc,\n",
        "        'random_auc': random_auc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'thresholds': thresholds\n",
        "    }\n"
      ],
      "metadata": {
        "id": "xZlWlh7zktrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Usage Example**\n",
        "**Load and Process Data**"
      ],
      "metadata": {
        "id": "3SU_LTh4kv1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = pd.read_csv('wearable_data.csv')  # Replace with actual file path\n",
        "seizure_labels = pd.read_csv('seizure_events.csv')  # Replace with actual file path\n",
        "\n",
        "processed_data = process_wearable_data(raw_data)\n"
      ],
      "metadata": {
        "id": "2mQb-joBkygo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initialize and Train the Forecaster**"
      ],
      "metadata": {
        "id": "X7b0TRpgkz2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forecaster = SeizureForecaster(prediction_horizon=30, sequence_length=60)\n",
        "X, y = forecaster.prepare_sequences(processed_data, seizure_labels)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "train_idx = int(len(X) * 0.8)\n",
        "X_train, y_train = X[:train_idx], y[:train_idx]\n",
        "X_val, y_val = X[train_idx:], y[train_idx:]\n",
        "\n",
        "# Train the model\n",
        "history = forecaster.train(train_data=(X_train, y_train), val_data=(X_val, y_val))\n"
      ],
      "metadata": {
        "id": "CErN5LS3k3uW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate Predictions and Evaluate**"
      ],
      "metadata": {
        "id": "PKnPSP9kk5JO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = forecaster.predict(X_val)\n",
        "random_predictions = np.random.random(len(y_val))\n",
        "metrics = evaluate_forecaster(y_val, predictions, random_predictions)\n",
        "\n",
        "print(f\"AUC-ROC: {metrics['auc_roc']:.2f}\")\n",
        "print(f\"Random AUC-ROC: {metrics['random_auc']:.2f}\")\n"
      ],
      "metadata": {
        "id": "I0XzquLDk6nf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}